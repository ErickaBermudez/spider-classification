{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e0af38",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b44416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebdf06",
   "metadata": {},
   "source": [
    "# Getting our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04594674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"data/train\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ca221",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"data/valid\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec724b1",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomContrast(0.5),\n",
    "        layers.RandomZoom(0.3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8898e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98e9a3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894c235",
   "metadata": {},
   "source": [
    "First we will get our MobileNetV2 model and use as a base.\n",
    "\n",
    "## MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed80421",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=image_size + (3,),\n",
    "    include_top=False,\n",
    "    weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing our MobileNetV2\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3071a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessed numpy.array or a tf.Tensor with type float32.\n",
    "The inputs pixel values are scaled between -1 and 1, sample-wise.\n",
    "'''\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=image_size + (3,))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(15)(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beec6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c20f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffffbcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss0, accuracy0 = model.evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84981e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d38114",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler \n",
    "'''\n",
    "EarlyStopping: Stop training when a monitored metric has stopped improving.\n",
    "In this case, it is the default, val_loss\n",
    "min_delta: Minimum change in the monitored quantity to qualify as an improvement\n",
    "patience: patience\n",
    "\n",
    "In this case, we are working only with 10 epochs, but in case there are more, it will be important.\n",
    "'''\n",
    "EarlyStop_callback = EarlyStopping(min_delta=0.001, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae44195",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train,\n",
    "                    epochs=12,\n",
    "                    validation_data=val,\n",
    "                   callbacks = [EarlyStop_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298f989d",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    \"data/test/Ladybird Mimic Spider/1.jpg\", target_size=image_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = predictions[0]\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"data/test\",\n",
    "    seed=1337,\n",
    "    image_size=image_size)\n",
    "\n",
    "class_names = [\n",
    "    'Black Widow',\n",
    "    'Blue Tarantula',\n",
    "    'Bold Jumper',\n",
    "    'Brown Grass Spider',\n",
    "    'Brown Recluse Spider',\n",
    "    'Deinopis Spider',\n",
    "    'Golden Orb Weaver',\n",
    "    'Hobo Spider',\n",
    "    'Huntsman Spider',\n",
    "    'Ladybird Mimic Spider',\n",
    "    'Peacock Spider',\n",
    "    'Red Knee Tarantula',\n",
    "    'Spiny-backed Orb-weaver',\n",
    "    'White Kneed Tarantula',\n",
    "    'Yellow Garden Spider'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae57ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "image_ids = []\n",
    "for image_batch, label_batch in test:\n",
    "    batch_predictions = model.predict_on_batch(image_batch)\n",
    "    batch_predictions = tf.nn.softmax(batch_predictions)\n",
    "    batch_predictions = batch_predictions.numpy()\n",
    "    \n",
    "    class_indices = np.argmax(batch_predictions, axis = 1)\n",
    "    predicted_class = []\n",
    "    for index in class_indices:\n",
    "        predicted_class.append(str(class_names[index]))\n",
    "    predictions += predicted_class\n",
    "    \n",
    "    str_img_ids = []\n",
    "    for img_id in label_batch:\n",
    "        str_img_ids.append(class_names[img_id])\n",
    "    \n",
    "#     image_ids += label_batch.numpy().tolist()\n",
    "    image_ids += str_img_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "results = pd.DataFrame({'actual': image_ids, 'prediction': predictions})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['actual','prediction'])\n",
    "confusion_matrix = pd.crosstab(df['actual'], df['prediction'], rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "sn.heatmap(confusion_matrix, annot=True, cmap='Greens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdac2f",
   "metadata": {},
   "source": [
    "# Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ab990",
   "metadata": {},
   "source": [
    "Our work is based on these authors:\n",
    "https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "https://www.kaggle.com/pranjalkumarnandi/baseline-with-keras-tf/data\n",
    "https://www.kaggle.com/enesaltun/spiders-resnet18\n",
    "https://www.kaggle.com/gpiosenka/inceptionresnetv2-98-acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41612774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
